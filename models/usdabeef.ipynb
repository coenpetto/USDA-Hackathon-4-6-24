{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "vbZNt1428lE4",
        "outputId": "5de1cc7a-2708-4ac8-ef9c-9d89b1ec0d1c"
      },
      "outputs": [],
      "source": [
        "# I have a tendency to import everthing on the planet so I hope u have ram\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import keras_tuner as kt\n",
        "import keras_cv as kcv\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2L\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "from tensorflow.keras.regularizers import l1, l2, L1L2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tifffile as tiff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import imagecodecs\n",
        "import cv2\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "CsSnPnrl9Jbn",
        "outputId": "2386e744-b564-43f7-f6f5-1ff08ec0abe9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('Path1/Path1-Model Training/Path1 Challenge Training Data.xlsx')\n",
        "directory = 'Path1/Path1-Model Training/Path1 Challenge Training Images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5qON0aq9KlH"
      },
      "outputs": [],
      "source": [
        "def load_images_from_folder(folder, target_size=(224, 224)):\n",
        "    images = []\n",
        "    files = sorted(os.listdir(folder))\n",
        "    for filename in files:\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            resized_img = cv2.resize(img, target_size)\n",
        "            images.append(resized_img)\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diMNmlPI9L0Y"
      },
      "outputs": [],
      "source": [
        "directory = 'Path1/Path1-Model Training/Path1 Challenge Training Images/'\n",
        "\n",
        "df = pd.read_excel('Path1/Path1-Model Training/Path1 Challenge Training Data.xlsx')\n",
        "df = df[df['Grade Category'] != 'Standard']\n",
        "\n",
        "grade_mapping = {'Select': 0, 'Low Choice': 1, 'Upper 2/3 Choice': 2, 'Prime': 3}\n",
        "class_names = \"Select\", \"Low Choice\", \"Upper 2/3 Choice\", \"Prime\"\n",
        "\n",
        "df['Label'] = df['Grade Category'].map(grade_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKXHQUMF9NNx"
      },
      "outputs": [],
      "source": [
        "file_list = sorted(os.listdir(directory))\n",
        "df_filtered = df[df['Filename'].isin(file_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br6FMDCD9OwL"
      },
      "outputs": [],
      "source": [
        "df_filtered.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFkzgIyS9QSL"
      },
      "outputs": [],
      "source": [
        "all_images = load_images_from_folder(directory, target_size=(224, 224))\n",
        "\n",
        "all_labels = []\n",
        "filtered_images = []\n",
        "\n",
        "# extract label from each filename\n",
        "for filename in file_list:\n",
        "    if filename in df_filtered['Filename'].values:\n",
        "        label = df_filtered[df_filtered['Filename'] == filename]['Label'].values[0]\n",
        "        all_labels.append(label)\n",
        "\n",
        "        #filter images because the first one file is not in the filtered df\n",
        "        filtered_images.append(all_images[file_list.index(filename)])\n",
        "\n",
        "# make them arrays\n",
        "all_labels = np.array(all_labels)\n",
        "filtered_images = np.array(filtered_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdYYfiQg9UMr"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data = train_test_split(df_filtered, test_size=0.2, random_state=42)\n",
        "\n",
        "# split the images themselves in case we do some visualizations\n",
        "train_images, validation_images, train_labels, validation_labels = train_test_split(\n",
        "    filtered_images,\n",
        "    all_labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCKEUNTg9Vnb"
      },
      "outputs": [],
      "source": [
        "print(df_filtered.tail())\n",
        "print(train_data['Label'].unique())\n",
        "print(validation_data['Label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0zznc--9XCV"
      },
      "outputs": [],
      "source": [
        "# one hot encoding allows for ml to digest categorical data as binary\n",
        "train_labels_one_hot = to_categorical(train_data['Label'], num_classes=4)\n",
        "validation_labels_one_hot = to_categorical(validation_data['Label'], num_classes=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U--Zanm9YlK"
      },
      "outputs": [],
      "source": [
        "#oversampling... not the greatest\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(filtered_images.reshape(-1, 224*224*3), all_labels)\n",
        "\n",
        "X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n",
        "y_resampled_one_hot = to_categorical(y_resampled, num_classes=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHOjiGRo9Zl9"
      },
      "outputs": [],
      "source": [
        "# under sampling\n",
        "sampling_strategy = {\n",
        "    1: 200,\n",
        "    2: 200,\n",
        "    0: 175,\n",
        "    3: 79\n",
        "}\n",
        "\n",
        "rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(filtered_images.reshape(-1, 224*224*3), all_labels)\n",
        "\n",
        "X_resampled = X_resampled.reshape(-1, 224, 224, 3)\n",
        "y_resampled_one_hot = to_categorical(y_resampled, num_classes=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-RQZxYu9a-r"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255, #normalize!\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest' #brendan said he likes this one\n",
        ")\n",
        "\n",
        "# inputs our images into the augment and preps into tensors for model\n",
        "train_generator = datagen.flow(\n",
        "    # X_resampled,\n",
        "    # y_resampled_one_hot,\n",
        "    all_images[train_data.index],\n",
        "    train_labels_one_hot,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# preps images for model\n",
        "validation_generator = datagen.flow(\n",
        "    all_images[validation_data.index],\n",
        "    validation_labels_one_hot,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwGqD4919ciQ"
      },
      "outputs": [],
      "source": [
        "image_filename = df['Filename'].iloc[0]  # first image\n",
        "\n",
        "image_path = os.path.join(directory, image_filename)\n",
        "\n",
        "# plot\n",
        "img = image.load_img(image_path, target_size=(224, 224))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Image: {image_filename}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8Yh1IKs9d_m"
      },
      "outputs": [],
      "source": [
        "# check  original balance\n",
        "class_counts = df_filtered['Grade Category'].value_counts()\n",
        "print(class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlDg6wWh9gKx"
      },
      "outputs": [],
      "source": [
        "#post under/oversampling\n",
        "\n",
        "unique_classes, counts = np.unique(y_resampled, return_counts=True)\n",
        "for cls, count in zip(unique_classes, counts):\n",
        "    print(f\"Class {cls}: {count} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIPwqYov9nV8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate class frequencies\n",
        "unique_classes, class_counts = np.unique(y_resampled, return_counts=True)\n",
        "\n",
        "# Calculate class weights\n",
        "total_samples = len(y_resampled)\n",
        "class_weights = {cls: total_samples / (len(unique_classes) * count) for cls, count in zip(unique_classes, class_counts)}\n",
        "\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEjaFtX99odn"
      },
      "outputs": [],
      "source": [
        "class_weights_dict = {\n",
        "    1: 0.5,\n",
        "    2: 1,\n",
        "    0: 1,\n",
        "    3: 1.5\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7FaXlIn9pj9"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG7uwSJe9q4E"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkEGw06A94V9"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer='adam', loss=kcv.losses.FocalLoss(), metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# TTRAINNNN\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator),\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# eval on validation\n",
        "loss, accuracy = model.evaluate(validation_generator, verbose=1)\n",
        "print(f\"Validation Loss: {loss}\")\n",
        "print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK9jKJxw-CzF"
      },
      "outputs": [],
      "source": [
        "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
